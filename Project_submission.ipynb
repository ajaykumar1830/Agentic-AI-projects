{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd7f0b-851f-4e87-af80-f4f2d1a27a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3c592-bef6-47c5-9d6c-4ec8a6a39dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateToken():\n",
    "    cwd = os.getcwd()\n",
    "    dotenv_path = os.path.join(cwd,'filepath')\n",
    "    load_dotenv(dotenv_path)\n",
    "    time_generated_str = os.getenv(\"TIME_GENERATED\")\n",
    "    print(time_generated_str)\n",
    "    TimeGenerated = datetime.fromisoformat(time_generated_str)\n",
    "    if TimeGenerated + timedelta(minutes=60) < datetime.now():\n",
    "        token_url = os.getenv(\"ISSUER_URL\")+\"/v1/token\"\n",
    "        print(token_url)\n",
    "        client_id = os.getenv(\"CLIENT_ID\")\n",
    "        client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "        scope = os.getenv(\"SCOPE\")\n",
    "        # Define the payload\n",
    "        payload = {\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"scope\": scope\n",
    "        }\n",
    "        # Make the POST request\n",
    "        response = requests.post(token_url, data=payload, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"})\n",
    "        print(response.json())\n",
    "        repsonse_json = response.json()\n",
    "        token = repsonse_json[\"access_token\"]\n",
    "        TimeGenerated = datetime.now()\n",
    "        # Update the .env file with the new token\n",
    "        with open('C:/Users/AK57630/auth.env', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        with open('.env', 'w') as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"OPENAI_API_KEY=\"):\n",
    "                    file.write(f\"OPENAI_API_KEY={token}\\n\")\n",
    "                elif line.startswith(\"TIME_GENERATED=\"):\n",
    "                    file.write(f\"TIME_GENERATED={TimeGenerated}\\n\")\n",
    "                else:\n",
    "                    file.write(line)    \n",
    "        os.environ.pop(\"OPENAI_API_KEY\", None)                \n",
    "        load_dotenv()\n",
    "        print(os.getenv(\"OPENAI_API_KEY\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc7c65-ca71-4231-a4ae-ed8d44045b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97c894-1afb-4cea-a6d9-4c780437c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "header_name = os.getenv('AI_GATEWAY_HEADER_NAME')\n",
    "header_value = os.getenv('AI_GATEWAY_REGISTRATION_ID')\n",
    "headers = {\n",
    "    header_name: header_value\n",
    "    }\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0,default_headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b15e7f-83b1-458b-b630-f2c1a71a7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyPDF2\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554a5b8-0c73-4105-831a-2c029d99e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the file \n",
    "file_name = os.getenv(\"FILEPATH\")\n",
    "with open(file_name,'rb') as file:\n",
    "    reader=PyPDF2.PdfReader(file)\n",
    "    #Extract text from all pages\n",
    "    study_material=\"\"\n",
    "    for page in reader.pages:\n",
    "        study_material+=page.extract_text()\n",
    "    #Now 'study_material' contains the text from PDF\n",
    "    print(study_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa613869-c916-4515-8e41-e1ad59c1fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Chain 1: Summarize the text\n",
    "summary_prompt = \"\"\"\n",
    "       Act as a study assistant, given the following study material,\n",
    "       generate a summary of the study material into key bullet points.\n",
    "\n",
    "       Study Material:\n",
    "       {study_material}\n",
    "\"\"\"\n",
    "prompt_template1 = ChatPromptTemplate.from_template(summary_prompt)\n",
    "llm_chain1 = (prompt_template1\n",
    "                  |\n",
    "              chatgpt\n",
    "                  |\n",
    "              StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4702869-6933-48e9-8995-f10c3bcf1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 2: Translate Customer Message to English\n",
    "prompt2 = \"\"\"\n",
    "  Act as a study assistant,\n",
    "  For the summary message delimited below by triple backticks,\n",
    "  Generate 5 multiple choice questions and also mention the correct answer at the end of each questions\n",
    " Summary:\n",
    "  ```{summary}```\n",
    "\"\"\"\n",
    "prompt_template2 = ChatPromptTemplate.from_template(prompt2)\n",
    "llm_chain2 = (prompt_template2\n",
    "                  |\n",
    "              chatgpt\n",
    "                  |\n",
    "              StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e927c-ead6-4410-9654-a607e55a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(summary=llm_chain1)\n",
    "      |\n",
    "    RunnablePassthrough.assign(quiz_questions=llm_chain2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c2b39-aa82-4605-afdb-4f8e01cd1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = final_chain.invoke({'study_material': study_material})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd305c-b2d2-4c0b-ab28-9173e219dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response[\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db1ad9-a0e3-4678-9109-12a46d94620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response[\"quiz_questions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429d0db-ba8e-4368-ad70-17b1a2be20d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
