{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbd7f0b-851f-4e87-af80-f4f2d1a27a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf3c592-bef6-47c5-9d6c-4ec8a6a39dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateToken():\n",
    "    cwd = os.getcwd()\n",
    "    dotenv_path = os.path.join(cwd,'C:/Users/AK57630/auth.env')\n",
    "    load_dotenv(dotenv_path)\n",
    "    time_generated_str = os.getenv(\"TIME_GENERATED\")\n",
    "    print(time_generated_str)\n",
    "    TimeGenerated = datetime.fromisoformat(time_generated_str)\n",
    "    if TimeGenerated + timedelta(minutes=60) < datetime.now():\n",
    "        token_url = os.getenv(\"ISSUER_URL\")+\"/v1/token\"\n",
    "        print(token_url)\n",
    "        client_id = os.getenv(\"CLIENT_ID\")\n",
    "        client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "        scope = os.getenv(\"SCOPE\")\n",
    "        # Define the payload\n",
    "        payload = {\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"scope\": scope\n",
    "        }\n",
    "        # Make the POST request\n",
    "        response = requests.post(token_url, data=payload, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"})\n",
    "        print(response.json())\n",
    "        repsonse_json = response.json()\n",
    "        token = repsonse_json[\"access_token\"]\n",
    "        TimeGenerated = datetime.now()\n",
    "        # Update the .env file with the new token\n",
    "        with open('C:/Users/AK57630/auth.env', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        with open('.env', 'w') as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"OPENAI_API_KEY=\"):\n",
    "                    file.write(f\"OPENAI_API_KEY={token}\\n\")\n",
    "                elif line.startswith(\"TIME_GENERATED=\"):\n",
    "                    file.write(f\"TIME_GENERATED={TimeGenerated}\\n\")\n",
    "                else:\n",
    "                    file.write(line)    \n",
    "        os.environ.pop(\"OPENAI_API_KEY\", None)                \n",
    "        load_dotenv()\n",
    "        print(os.getenv(\"OPENAI_API_KEY\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecc7c65-ca71-4231-a4ae-ed8d44045b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-13 16:16:11.547398\n",
      "https://sso.johndeere.com/oauth2/aushh24tmyH9xSbQ21t7/v1/token\n",
      "{'token_type': 'Bearer', 'expires_in': 3600, 'access_token': 'eyJraWQiOiJKU1V5UWRZVVlFR280ZUQ0V2Ntbk5pWXB0VzREdHFySUxnVXEwQm9mdnBrIiwiYWxnIjoiUlMyNTYifQ.eyJ2ZXIiOjEsImp0aSI6IkFULkx5bVR3bjBOczZfVTVnTFpTbDR3WkdPR1pZbE5KYTZuamNBSzNuZzJPSTQiLCJpc3MiOiJodHRwczovL3Nzby5qb2huZGVlcmUuY29tL29hdXRoMi9hdXNoaDI0dG15SDl4U2JRMjF0NyIsImF1ZCI6Im1sb3BzLXBsYXRmb3JtIiwiaWF0IjoxNzQ2MjQxNzU4LCJleHAiOjE3NDYyNDUzNTgsImNpZCI6IjBvYTEzNmVjZmJqT1hQQ2NXMXQ4Iiwic2NwIjpbIm1sb3BzLmRlZXJlLmNvbS9tb2RlbC1kZXBsb3ltZW50cy5sbG0ucmVnaW9uLXJlc3RyaWN0ZWQtaW52b2NhdGlvbnMiXSwic3ViIjoiMG9hMTM2ZWNmYmpPWFBDY1cxdDgifQ.N3FBHMTslnaRZHW9Za97XlmivrfUXySfw6uGma-rHGuWiH8Q0ChxyMs_iKkUdpDkMS4CJnNKO9_5DFp-rOVA6x-z8X6AHvidFOxW0NiGlVN9X1iz4-jo6S3dkkg1hGan-_VX-neMsf25LYRPN-7yjcWT-JdBohBvIMoKj4dSDoq7s-vxdwXHJW6Ow9P7mPP7ab1z52PqSXKpa_ET-fOZIXAbFhkTTVjO1VAzl4st5p9nfFxCeMirMq3F7FO87-dVVvk_tRlkcYvjkwxGUHIlPwmWckCdhyjgvoukJuPo30Th1e5iZ3TIxcONl5MFBK4UrIgMIjxQuhDNr4DmEW-8LA', 'scope': 'mlops.deere.com/model-deployments.llm.region-restricted-invocations'}\n",
      "eyJraWQiOiJKU1V5UWRZVVlFR280ZUQ0V2Ntbk5pWXB0VzREdHFySUxnVXEwQm9mdnBrIiwiYWxnIjoiUlMyNTYifQ.eyJ2ZXIiOjEsImp0aSI6IkFULkx5bVR3bjBOczZfVTVnTFpTbDR3WkdPR1pZbE5KYTZuamNBSzNuZzJPSTQiLCJpc3MiOiJodHRwczovL3Nzby5qb2huZGVlcmUuY29tL29hdXRoMi9hdXNoaDI0dG15SDl4U2JRMjF0NyIsImF1ZCI6Im1sb3BzLXBsYXRmb3JtIiwiaWF0IjoxNzQ2MjQxNzU4LCJleHAiOjE3NDYyNDUzNTgsImNpZCI6IjBvYTEzNmVjZmJqT1hQQ2NXMXQ4Iiwic2NwIjpbIm1sb3BzLmRlZXJlLmNvbS9tb2RlbC1kZXBsb3ltZW50cy5sbG0ucmVnaW9uLXJlc3RyaWN0ZWQtaW52b2NhdGlvbnMiXSwic3ViIjoiMG9hMTM2ZWNmYmpPWFBDY1cxdDgifQ.N3FBHMTslnaRZHW9Za97XlmivrfUXySfw6uGma-rHGuWiH8Q0ChxyMs_iKkUdpDkMS4CJnNKO9_5DFp-rOVA6x-z8X6AHvidFOxW0NiGlVN9X1iz4-jo6S3dkkg1hGan-_VX-neMsf25LYRPN-7yjcWT-JdBohBvIMoKj4dSDoq7s-vxdwXHJW6Ow9P7mPP7ab1z52PqSXKpa_ET-fOZIXAbFhkTTVjO1VAzl4st5p9nfFxCeMirMq3F7FO87-dVVvk_tRlkcYvjkwxGUHIlPwmWckCdhyjgvoukJuPo30Th1e5iZ3TIxcONl5MFBK4UrIgMIjxQuhDNr4DmEW-8LA\n"
     ]
    }
   ],
   "source": [
    "generateToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b97c894-1afb-4cea-a6d9-4c780437c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "header_name = os.getenv('AI_GATEWAY_HEADER_NAME')\n",
    "header_value = os.getenv('AI_GATEWAY_REGISTRATION_ID')\n",
    "headers = {\n",
    "    header_name: header_value\n",
    "    }\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini-2024-07-18\", temperature=0,default_headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b15e7f-83b1-458b-b630-f2c1a71a7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyPDF2\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9554a5b8-0c73-4105-831a-2c029d99e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What\n",
      "is\n",
      "Prompt\n",
      "Engineering?\n",
      "Prompt\n",
      "engineering\n",
      "is\n",
      "a\n",
      "practice\n",
      "within\n",
      "natural\n",
      "language\n",
      "processing\n",
      "(NLP)\n",
      "in\n",
      "artificial\n",
      "intelligence,\n",
      "where\n",
      "text\n",
      "is\n",
      "used\n",
      "to\n",
      "describe\n",
      "the\n",
      "task\n",
      "the\n",
      "AI\n",
      "should\n",
      "perform.\n",
      "Guided\n",
      "by\n",
      "this\n",
      "input,\n",
      "the\n",
      "AI\n",
      "generates\n",
      "an\n",
      "output,\n",
      "which\n",
      "could\n",
      "take\n",
      "various\n",
      "forms.\n",
      "The\n",
      "goal\n",
      "is\n",
      "to\n",
      "use\n",
      "human-understandable\n",
      "text\n",
      "to\n",
      "interact\n",
      "conversationally\n",
      "with\n",
      "models,\n",
      "allowing\n",
      "for\n",
      "flexibility\n",
      "in\n",
      "the\n",
      "model’ s\n",
      "performance\n",
      "due\n",
      "to\n",
      "the\n",
      "task\n",
      "description\n",
      "embedded\n",
      "in\n",
      "the\n",
      "prompt.\n",
      "What\n",
      "are\n",
      "Prompts?\n",
      "Prompts\n",
      "are\n",
      "detailed\n",
      "descriptions\n",
      "of\n",
      "the\n",
      "desired\n",
      "output\n",
      "from\n",
      "an\n",
      "AI\n",
      "model.\n",
      "They\n",
      "represent\n",
      "the\n",
      "interaction\n",
      "between\n",
      "the\n",
      "user\n",
      "and\n",
      "the\n",
      "model\n",
      "and\n",
      "help\n",
      "define\n",
      "what\n",
      "the\n",
      "AI\n",
      "is\n",
      "expected\n",
      "to\n",
      "do.\n",
      "The\n",
      "effectiveness\n",
      "of\n",
      "prompt\n",
      "engineering\n",
      "largely\n",
      "depends\n",
      "on\n",
      "how\n",
      "well\n",
      "the\n",
      "prompt\n",
      "is\n",
      "designed\n",
      "to\n",
      "guide\n",
      "the\n",
      "model.\n",
      "Examples\n",
      "of\n",
      "Prompt\n",
      "Engineering\n",
      "Prompts\n",
      "in\n",
      "large\n",
      "language\n",
      "models\n",
      "(LLMs)\n",
      "like\n",
      "ChatGPT\n",
      "or\n",
      "GPT -3\n",
      "can\n",
      "range\n",
      "from\n",
      "simple\n",
      "text\n",
      "queries\n",
      "to\n",
      "complex\n",
      "instructions.\n",
      "The\n",
      "key\n",
      "to\n",
      "effective\n",
      "prompting\n",
      "is\n",
      "providing\n",
      "sufficient\n",
      "detail.\n",
      "Examples\n",
      "of\n",
      "prompts\n",
      "for\n",
      "various\n",
      "tasks\n",
      "include:\n",
      "Text\n",
      "Prompts\n",
      "(ChatGPT,\n",
      "GPT):●\n",
      "\"What’ s\n",
      "the\n",
      "difference\n",
      "between\n",
      "generative\n",
      "AI\n",
      "and\n",
      "traditional\n",
      "AI?\"\n",
      "●\n",
      "\"Provide\n",
      "10\n",
      "variations\n",
      "for\n",
      "the\n",
      "headline,\n",
      "'Top\n",
      "generative\n",
      "AI\n",
      "use\n",
      "cases\n",
      "for\n",
      "the\n",
      "enterprise.'\"\n",
      "●\n",
      "\"Write\n",
      "an\n",
      "outline\n",
      "for\n",
      "an\n",
      "article\n",
      "on\n",
      "the\n",
      "benefits\n",
      "of\n",
      "generative\n",
      "AI\n",
      "for\n",
      "marketing.\"\n",
      "●\n",
      "\"Generate\n",
      "300\n",
      "words\n",
      "for\n",
      "each\n",
      "section\n",
      "of\n",
      "an\n",
      "article\n",
      "on\n",
      "the\n",
      "benefits\n",
      "of\n",
      "generative\n",
      "AI.\"\n",
      "●\n",
      "\"Craft\n",
      "a\n",
      "100-word\n",
      "product\n",
      "description\n",
      "for\n",
      "ProductXYZ\n",
      "in\n",
      "five\n",
      "styles.\"\n",
      "●\n",
      "\"Define\n",
      "types\n",
      "of\n",
      "prompt\n",
      "engineering\n",
      "basics\n",
      "in\n",
      "iambic\n",
      "pentameter ,\n",
      "Shakespearean\n",
      "style.\"\n",
      "Code\n",
      "Prompts\n",
      "(ChatGPT,\n",
      "Codex):\n",
      "●\n",
      "\"Act\n",
      "as\n",
      "an\n",
      "ASCII\n",
      "artist\n",
      "translating\n",
      "object\n",
      "names\n",
      "into\n",
      "ASCII\n",
      "code.\"\n",
      "●\n",
      "\"Identify\n",
      "mistakes\n",
      "in\n",
      "the\n",
      "following\n",
      "code.\"\n",
      "●\n",
      "\"Write\n",
      "a\n",
      "function\n",
      "to\n",
      "multiply\n",
      "two\n",
      "numbers\n",
      "and\n",
      "return\n",
      "the\n",
      "result.\"\n",
      "●\n",
      "\"Develop\n",
      "a\n",
      "basic\n",
      "REST\n",
      "API\n",
      "in\n",
      "Python.\"\n",
      "●\n",
      "\"Explain\n",
      "the\n",
      "function\n",
      "of\n",
      "this\n",
      "code\n",
      "snippet.\"\n",
      "●\n",
      "\"Simplify\n",
      "the\n",
      "following\n",
      "code.\"\n",
      "Image\n",
      "Prompts\n",
      "(Stable\n",
      "Diffusion,\n",
      "Midjourney,\n",
      "DALL-E\n",
      "2):\n",
      "●\n",
      "\"Depict\n",
      "a\n",
      "dog\n",
      "in\n",
      "a\n",
      "car\n",
      "wearing\n",
      "sunglasses\n",
      "and\n",
      "a\n",
      "hat\n",
      "in\n",
      "the\n",
      "style\n",
      "of\n",
      "Salvador\n",
      "Dali.\"\n",
      "●\n",
      "\"Illustrate\n",
      "a\n",
      "lizard\n",
      "on\n",
      "the\n",
      "beach\n",
      "in\n",
      "claymation\n",
      "art\n",
      "style.\"●\n",
      "\"Create\n",
      "an\n",
      "image\n",
      "of\n",
      "a\n",
      "man\n",
      "using\n",
      "a\n",
      "phone\n",
      "on\n",
      "the\n",
      "subway\n",
      "in\n",
      "4K\n",
      "resolution\n",
      "with\n",
      "bokeh\n",
      "blur.\"\n",
      "●\n",
      "\"Design\n",
      "a\n",
      "sticker\n",
      "illustration\n",
      "of\n",
      "a\n",
      "woman\n",
      "drinking\n",
      "coffee\n",
      "at\n",
      "a\n",
      "table\n",
      "with\n",
      "a\n",
      "checkered\n",
      "tablecloth.\"\n",
      "●\n",
      "\"Visualize\n",
      "a\n",
      "jungle\n",
      "forest\n",
      "with\n",
      "cinematic\n",
      "lighting\n",
      "and\n",
      "nature\n",
      "photography .\"\n",
      "●\n",
      "\"Generate\n",
      "a\n",
      "first-person\n",
      "view\n",
      "of\n",
      "looking\n",
      "out\n",
      "at\n",
      "orange\n",
      "clouds\n",
      "during\n",
      "sunrise.\"\n",
      "How\n",
      "to\n",
      "Engineer\n",
      "AI\n",
      "Prompts\n",
      "The\n",
      "quality\n",
      "of\n",
      "a\n",
      "prompt\n",
      "is\n",
      "critical.\n",
      "To\n",
      "improve\n",
      "prompt\n",
      "effectiveness,\n",
      "consider\n",
      "the\n",
      "following\n",
      "tips:\n",
      "●\n",
      "Role\n",
      "Playing\n",
      ":\n",
      "Make\n",
      "the\n",
      "model\n",
      "act\n",
      "as\n",
      "a\n",
      "specific\n",
      "entity\n",
      "(e.g.,\n",
      "teacher ,\n",
      "code\n",
      "editor ,\n",
      "interviewer)\n",
      "to\n",
      "tailor\n",
      "the\n",
      "interaction\n",
      "and\n",
      "target\n",
      "a\n",
      "specific\n",
      "outcome.\n",
      "●\n",
      "Clarity\n",
      ":\n",
      "Remove\n",
      "ambiguity\n",
      "by\n",
      "being\n",
      "concise.\n",
      "Avoid\n",
      "unnecessary\n",
      "details\n",
      "that\n",
      "might\n",
      "confuse\n",
      "the\n",
      "model.\n",
      "●\n",
      "Specification\n",
      ":\n",
      "Be\n",
      "specific\n",
      "in\n",
      "your\n",
      "instructions\n",
      "to\n",
      "direct\n",
      "the\n",
      "model’ s\n",
      "output\n",
      "clearly .\n",
      "●\n",
      "Consistency\n",
      ":\n",
      "Maintain\n",
      "a\n",
      "consistent\n",
      "tone\n",
      "and\n",
      "flow\n",
      "in\n",
      "the\n",
      "prompt\n",
      "to\n",
      "ensure\n",
      "coherent\n",
      "and\n",
      "legible\n",
      "responses.\n",
      "Elements\n",
      "of\n",
      "a\n",
      "Prompt\n",
      "The\n",
      "components\n",
      "that\n",
      "make\n",
      "up\n",
      "a\n",
      "prompt\n",
      "include:●\n",
      "Instruction\n",
      ":\n",
      "A\n",
      "statement\n",
      "telling\n",
      "the\n",
      "model\n",
      "what\n",
      "task\n",
      "to\n",
      "perform.\n",
      "●\n",
      "Context\n",
      ":\n",
      "Background\n",
      "information\n",
      "that\n",
      "helps\n",
      "the\n",
      "model\n",
      "understand\n",
      "the\n",
      "problem\n",
      "at\n",
      "hand.\n",
      "●\n",
      "Input\n",
      "Data\n",
      ":\n",
      "The\n",
      "input\n",
      "data\n",
      "given\n",
      "to\n",
      "the\n",
      "model\n",
      "to\n",
      "process.\n",
      "●\n",
      "Output\n",
      "Indicator\n",
      ":\n",
      "A\n",
      "specification\n",
      "of\n",
      "the\n",
      "expected\n",
      "output\n",
      "format\n",
      "(e.g.,\n",
      "code,\n",
      "text,\n",
      "image).\n",
      "Standard\n",
      "Prompt\n",
      "Patterns\n",
      "Prompts\n",
      "generally\n",
      "follow\n",
      "specific\n",
      "formats:\n",
      "User-Model\n",
      "Interaction\n",
      ":\n",
      "User:\n",
      "<Instruction>\n",
      "Model:\n",
      "<Response>\n",
      "Few-Shot\n",
      "Prompting\n",
      ":\n",
      "Provides\n",
      "a\n",
      "few\n",
      "examples\n",
      "of\n",
      "the\n",
      "task\n",
      "to\n",
      "guide\n",
      "the\n",
      "model.\n",
      "<Instruction>\n",
      "<Response><Instruction>\n",
      "<Response>\n",
      "<Instruction>\n",
      "<Response>\n",
      "Question-and-Answer\n",
      "Pattern\n",
      ":\n",
      "makefile\n",
      "Copy\n",
      "code\n",
      "Q:\n",
      "<Question>?\n",
      "A:\n",
      "<Answer>\n",
      "Q:\n",
      "<Question>?\n",
      "A:\n",
      "<Answer>●\n",
      "Prompting\n",
      "Techniques\n",
      "There\n",
      "are\n",
      "several\n",
      "advanced\n",
      "techniques\n",
      "for\n",
      "crafting\n",
      "effective\n",
      "prompts:\n",
      "1.\n",
      "Zero-Shot\n",
      "Prompting\n",
      ":\n",
      "The\n",
      "model\n",
      "performs\n",
      "a\n",
      "task\n",
      "without\n",
      "having\n",
      "been\n",
      "specifically\n",
      "trained\n",
      "on\n",
      "it,\n",
      "relying\n",
      "on\n",
      "its\n",
      "general\n",
      "knowledge.\n",
      "Example:\n",
      "Prompt:\n",
      "\"Classify\n",
      "the\n",
      "text\n",
      "into\n",
      "neutral,\n",
      "negative,\n",
      "or\n",
      "positive.\"\n",
      "Text:\n",
      "\"I\n",
      "think\n",
      "the\n",
      "presentation\n",
      "was\n",
      "awesome.\"\n",
      "Sentiment:\n",
      "Positive\n",
      "2.\n",
      "Few-Shot\n",
      "Prompting\n",
      "/\n",
      "In-Context\n",
      "Learning\n",
      ":\n",
      "The\n",
      "model\n",
      "is\n",
      "given\n",
      "a\n",
      "few\n",
      "examples\n",
      "to\n",
      "build\n",
      "upon,\n",
      "which\n",
      "helps\n",
      "it\n",
      "perform\n",
      "tasks\n",
      "more\n",
      "effectively .\n",
      "3.\n",
      "Chain-of-Thought\n",
      "(CoT)\n",
      ":\n",
      "This\n",
      "technique\n",
      "allows\n",
      "the\n",
      "model\n",
      "to\n",
      "process\n",
      "complex\n",
      "reasoning\n",
      "by\n",
      "breaking\n",
      "down\n",
      "the\n",
      "task\n",
      "into\n",
      "intermediate\n",
      "steps,\n",
      "improving\n",
      "output\n",
      "quality .\n",
      "What\n",
      "to\n",
      "Avoid\n",
      "When\n",
      "Creating\n",
      "Prompts\n",
      "Avoid\n",
      "the\n",
      "following\n",
      "pitfalls\n",
      "when\n",
      "creating\n",
      "prompts:\n",
      "●\n",
      "Information\n",
      "Overload\n",
      ":\n",
      "Too\n",
      "much\n",
      "detail\n",
      "can\n",
      "cause\n",
      "ambiguity\n",
      "and\n",
      "reduce\n",
      "the\n",
      "accuracy\n",
      "of\n",
      "responses.●\n",
      "Open-Ended\n",
      "Questions\n",
      ":\n",
      "Avoid\n",
      "vague\n",
      "or\n",
      "non-specific\n",
      "questions\n",
      "that\n",
      "may\n",
      "lead\n",
      "to\n",
      "imprecise\n",
      "responses.\n",
      "●\n",
      "Poor\n",
      "Use\n",
      "of\n",
      "Constraints\n",
      ":\n",
      "Avoid\n",
      "giving\n",
      "the\n",
      "model\n",
      "too\n",
      "much\n",
      "freedom.\n",
      "Instead,\n",
      "specify\n",
      "boundaries\n",
      "or\n",
      "requirements\n",
      "to\n",
      "guide\n",
      "the\n",
      "output\n",
      "more\n",
      "effectively .\n"
     ]
    }
   ],
   "source": [
    "#Open the file \n",
    "file_name = os.getenv(\"FILEPATH\")\n",
    "with open(file_name,'rb') as file:\n",
    "    reader=PyPDF2.PdfReader(file)\n",
    "    #Extract text from all pages\n",
    "    study_material=\"\"\n",
    "    for page in reader.pages:\n",
    "        study_material+=page.extract_text()\n",
    "    #Now 'study_material' contains the text from PDF\n",
    "    print(study_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa613869-c916-4515-8e41-e1ad59c1fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Chain 1: Summarize the text\n",
    "summary_prompt = \"\"\"\n",
    "       Act as a study assistant, given the following study material,\n",
    "       generate a summary of the study material into key bullet points.\n",
    "\n",
    "       Study Material:\n",
    "       {study_material}\n",
    "\"\"\"\n",
    "prompt_template1 = ChatPromptTemplate.from_template(summary_prompt)\n",
    "llm_chain1 = (prompt_template1\n",
    "                  |\n",
    "              chatgpt\n",
    "                  |\n",
    "              StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4702869-6933-48e9-8995-f10c3bcf1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 2: Translate Customer Message to English\n",
    "prompt2 = \"\"\"\n",
    "  Act as a study assistant,\n",
    "  For the summary message delimited below by triple backticks,\n",
    "  Generate 5 multiple choice questions and also mention the correct answer at the end of each questions\n",
    " Summary:\n",
    "  ```{summary}```\n",
    "\"\"\"\n",
    "prompt_template2 = ChatPromptTemplate.from_template(prompt2)\n",
    "llm_chain2 = (prompt_template2\n",
    "                  |\n",
    "              chatgpt\n",
    "                  |\n",
    "              StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98e927c-ead6-4410-9654-a607e55a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(summary=llm_chain1)\n",
    "      |\n",
    "    RunnablePassthrough.assign(quiz_questions=llm_chain2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7c2b39-aa82-4605-afdb-4f8e01cd1f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_material': 'What\\nis\\nPrompt\\nEngineering?\\nPrompt\\nengineering\\nis\\na\\npractice\\nwithin\\nnatural\\nlanguage\\nprocessing\\n(NLP)\\nin\\nartificial\\nintelligence,\\nwhere\\ntext\\nis\\nused\\nto\\ndescribe\\nthe\\ntask\\nthe\\nAI\\nshould\\nperform.\\nGuided\\nby\\nthis\\ninput,\\nthe\\nAI\\ngenerates\\nan\\noutput,\\nwhich\\ncould\\ntake\\nvarious\\nforms.\\nThe\\ngoal\\nis\\nto\\nuse\\nhuman-understandable\\ntext\\nto\\ninteract\\nconversationally\\nwith\\nmodels,\\nallowing\\nfor\\nflexibility\\nin\\nthe\\nmodel’ s\\nperformance\\ndue\\nto\\nthe\\ntask\\ndescription\\nembedded\\nin\\nthe\\nprompt.\\nWhat\\nare\\nPrompts?\\nPrompts\\nare\\ndetailed\\ndescriptions\\nof\\nthe\\ndesired\\noutput\\nfrom\\nan\\nAI\\nmodel.\\nThey\\nrepresent\\nthe\\ninteraction\\nbetween\\nthe\\nuser\\nand\\nthe\\nmodel\\nand\\nhelp\\ndefine\\nwhat\\nthe\\nAI\\nis\\nexpected\\nto\\ndo.\\nThe\\neffectiveness\\nof\\nprompt\\nengineering\\nlargely\\ndepends\\non\\nhow\\nwell\\nthe\\nprompt\\nis\\ndesigned\\nto\\nguide\\nthe\\nmodel.\\nExamples\\nof\\nPrompt\\nEngineering\\nPrompts\\nin\\nlarge\\nlanguage\\nmodels\\n(LLMs)\\nlike\\nChatGPT\\nor\\nGPT -3\\ncan\\nrange\\nfrom\\nsimple\\ntext\\nqueries\\nto\\ncomplex\\ninstructions.\\nThe\\nkey\\nto\\neffective\\nprompting\\nis\\nproviding\\nsufficient\\ndetail.\\nExamples\\nof\\nprompts\\nfor\\nvarious\\ntasks\\ninclude:\\nText\\nPrompts\\n(ChatGPT,\\nGPT):●\\n\"What’ s\\nthe\\ndifference\\nbetween\\ngenerative\\nAI\\nand\\ntraditional\\nAI?\"\\n●\\n\"Provide\\n10\\nvariations\\nfor\\nthe\\nheadline,\\n\\'Top\\ngenerative\\nAI\\nuse\\ncases\\nfor\\nthe\\nenterprise.\\'\"\\n●\\n\"Write\\nan\\noutline\\nfor\\nan\\narticle\\non\\nthe\\nbenefits\\nof\\ngenerative\\nAI\\nfor\\nmarketing.\"\\n●\\n\"Generate\\n300\\nwords\\nfor\\neach\\nsection\\nof\\nan\\narticle\\non\\nthe\\nbenefits\\nof\\ngenerative\\nAI.\"\\n●\\n\"Craft\\na\\n100-word\\nproduct\\ndescription\\nfor\\nProductXYZ\\nin\\nfive\\nstyles.\"\\n●\\n\"Define\\ntypes\\nof\\nprompt\\nengineering\\nbasics\\nin\\niambic\\npentameter ,\\nShakespearean\\nstyle.\"\\nCode\\nPrompts\\n(ChatGPT,\\nCodex):\\n●\\n\"Act\\nas\\nan\\nASCII\\nartist\\ntranslating\\nobject\\nnames\\ninto\\nASCII\\ncode.\"\\n●\\n\"Identify\\nmistakes\\nin\\nthe\\nfollowing\\ncode.\"\\n●\\n\"Write\\na\\nfunction\\nto\\nmultiply\\ntwo\\nnumbers\\nand\\nreturn\\nthe\\nresult.\"\\n●\\n\"Develop\\na\\nbasic\\nREST\\nAPI\\nin\\nPython.\"\\n●\\n\"Explain\\nthe\\nfunction\\nof\\nthis\\ncode\\nsnippet.\"\\n●\\n\"Simplify\\nthe\\nfollowing\\ncode.\"\\nImage\\nPrompts\\n(Stable\\nDiffusion,\\nMidjourney,\\nDALL-E\\n2):\\n●\\n\"Depict\\na\\ndog\\nin\\na\\ncar\\nwearing\\nsunglasses\\nand\\na\\nhat\\nin\\nthe\\nstyle\\nof\\nSalvador\\nDali.\"\\n●\\n\"Illustrate\\na\\nlizard\\non\\nthe\\nbeach\\nin\\nclaymation\\nart\\nstyle.\"●\\n\"Create\\nan\\nimage\\nof\\na\\nman\\nusing\\na\\nphone\\non\\nthe\\nsubway\\nin\\n4K\\nresolution\\nwith\\nbokeh\\nblur.\"\\n●\\n\"Design\\na\\nsticker\\nillustration\\nof\\na\\nwoman\\ndrinking\\ncoffee\\nat\\na\\ntable\\nwith\\na\\ncheckered\\ntablecloth.\"\\n●\\n\"Visualize\\na\\njungle\\nforest\\nwith\\ncinematic\\nlighting\\nand\\nnature\\nphotography .\"\\n●\\n\"Generate\\na\\nfirst-person\\nview\\nof\\nlooking\\nout\\nat\\norange\\nclouds\\nduring\\nsunrise.\"\\nHow\\nto\\nEngineer\\nAI\\nPrompts\\nThe\\nquality\\nof\\na\\nprompt\\nis\\ncritical.\\nTo\\nimprove\\nprompt\\neffectiveness,\\nconsider\\nthe\\nfollowing\\ntips:\\n●\\nRole\\nPlaying\\n:\\nMake\\nthe\\nmodel\\nact\\nas\\na\\nspecific\\nentity\\n(e.g.,\\nteacher ,\\ncode\\neditor ,\\ninterviewer)\\nto\\ntailor\\nthe\\ninteraction\\nand\\ntarget\\na\\nspecific\\noutcome.\\n●\\nClarity\\n:\\nRemove\\nambiguity\\nby\\nbeing\\nconcise.\\nAvoid\\nunnecessary\\ndetails\\nthat\\nmight\\nconfuse\\nthe\\nmodel.\\n●\\nSpecification\\n:\\nBe\\nspecific\\nin\\nyour\\ninstructions\\nto\\ndirect\\nthe\\nmodel’ s\\noutput\\nclearly .\\n●\\nConsistency\\n:\\nMaintain\\na\\nconsistent\\ntone\\nand\\nflow\\nin\\nthe\\nprompt\\nto\\nensure\\ncoherent\\nand\\nlegible\\nresponses.\\nElements\\nof\\na\\nPrompt\\nThe\\ncomponents\\nthat\\nmake\\nup\\na\\nprompt\\ninclude:●\\nInstruction\\n:\\nA\\nstatement\\ntelling\\nthe\\nmodel\\nwhat\\ntask\\nto\\nperform.\\n●\\nContext\\n:\\nBackground\\ninformation\\nthat\\nhelps\\nthe\\nmodel\\nunderstand\\nthe\\nproblem\\nat\\nhand.\\n●\\nInput\\nData\\n:\\nThe\\ninput\\ndata\\ngiven\\nto\\nthe\\nmodel\\nto\\nprocess.\\n●\\nOutput\\nIndicator\\n:\\nA\\nspecification\\nof\\nthe\\nexpected\\noutput\\nformat\\n(e.g.,\\ncode,\\ntext,\\nimage).\\nStandard\\nPrompt\\nPatterns\\nPrompts\\ngenerally\\nfollow\\nspecific\\nformats:\\nUser-Model\\nInteraction\\n:\\nUser:\\n<Instruction>\\nModel:\\n<Response>\\nFew-Shot\\nPrompting\\n:\\nProvides\\na\\nfew\\nexamples\\nof\\nthe\\ntask\\nto\\nguide\\nthe\\nmodel.\\n<Instruction>\\n<Response><Instruction>\\n<Response>\\n<Instruction>\\n<Response>\\nQuestion-and-Answer\\nPattern\\n:\\nmakefile\\nCopy\\ncode\\nQ:\\n<Question>?\\nA:\\n<Answer>\\nQ:\\n<Question>?\\nA:\\n<Answer>●\\nPrompting\\nTechniques\\nThere\\nare\\nseveral\\nadvanced\\ntechniques\\nfor\\ncrafting\\neffective\\nprompts:\\n1.\\nZero-Shot\\nPrompting\\n:\\nThe\\nmodel\\nperforms\\na\\ntask\\nwithout\\nhaving\\nbeen\\nspecifically\\ntrained\\non\\nit,\\nrelying\\non\\nits\\ngeneral\\nknowledge.\\nExample:\\nPrompt:\\n\"Classify\\nthe\\ntext\\ninto\\nneutral,\\nnegative,\\nor\\npositive.\"\\nText:\\n\"I\\nthink\\nthe\\npresentation\\nwas\\nawesome.\"\\nSentiment:\\nPositive\\n2.\\nFew-Shot\\nPrompting\\n/\\nIn-Context\\nLearning\\n:\\nThe\\nmodel\\nis\\ngiven\\na\\nfew\\nexamples\\nto\\nbuild\\nupon,\\nwhich\\nhelps\\nit\\nperform\\ntasks\\nmore\\neffectively .\\n3.\\nChain-of-Thought\\n(CoT)\\n:\\nThis\\ntechnique\\nallows\\nthe\\nmodel\\nto\\nprocess\\ncomplex\\nreasoning\\nby\\nbreaking\\ndown\\nthe\\ntask\\ninto\\nintermediate\\nsteps,\\nimproving\\noutput\\nquality .\\nWhat\\nto\\nAvoid\\nWhen\\nCreating\\nPrompts\\nAvoid\\nthe\\nfollowing\\npitfalls\\nwhen\\ncreating\\nprompts:\\n●\\nInformation\\nOverload\\n:\\nToo\\nmuch\\ndetail\\ncan\\ncause\\nambiguity\\nand\\nreduce\\nthe\\naccuracy\\nof\\nresponses.●\\nOpen-Ended\\nQuestions\\n:\\nAvoid\\nvague\\nor\\nnon-specific\\nquestions\\nthat\\nmay\\nlead\\nto\\nimprecise\\nresponses.\\n●\\nPoor\\nUse\\nof\\nConstraints\\n:\\nAvoid\\ngiving\\nthe\\nmodel\\ntoo\\nmuch\\nfreedom.\\nInstead,\\nspecify\\nboundaries\\nor\\nrequirements\\nto\\nguide\\nthe\\noutput\\nmore\\neffectively .',\n",
       " 'summary': '### Summary of Prompt Engineering\\n\\n- **Definition**: \\n  - Prompt engineering is a practice in natural language processing (NLP) where text describes the task for AI to perform, guiding the AI to generate various outputs.\\n\\n- **Purpose of Prompts**: \\n  - Prompts are detailed descriptions of desired outputs, defining user-model interactions and guiding AI performance.\\n\\n- **Effectiveness**: \\n  - The success of prompt engineering depends on the design and clarity of the prompt.\\n\\n- **Examples of Prompts**:\\n  - **Text Prompts**: \\n    - Questions or tasks for language models (e.g., \"What’s the difference between generative AI and traditional AI?\").\\n  - **Code Prompts**: \\n    - Instructions for coding tasks (e.g., \"Write a function to multiply two numbers.\").\\n  - **Image Prompts**: \\n    - Descriptions for generating images (e.g., \"Depict a dog in a car wearing sunglasses.\").\\n  \\n- **Tips for Effective Prompt Engineering**:\\n  - **Role Playing**: Specify the model\\'s role to tailor interactions.\\n  - **Clarity**: Be concise and avoid ambiguity.\\n  - **Specification**: Provide clear and specific instructions.\\n  - **Consistency**: Maintain a coherent tone and flow.\\n\\n- **Elements of a Prompt**:\\n  - **Instruction**: Task directive for the model.\\n  - **Context**: Background information for understanding.\\n  - **Input Data**: Data provided for processing.\\n  - **Output Indicator**: Expected output format specification.\\n\\n- **Standard Prompt Patterns**:\\n  - **User-Model Interaction**: Direct instruction-response format.\\n  - **Few-Shot Prompting**: Providing examples to guide the model.\\n  - **Question-and-Answer Pattern**: Structured Q&A format.\\n\\n- **Advanced Prompting Techniques**:\\n  - **Zero-Shot Prompting**: Task performance without specific training.\\n  - **Few-Shot Prompting/In-Context Learning**: Using examples to enhance task performance.\\n  - **Chain-of-Thought (CoT)**: Breaking down complex tasks into steps for better reasoning.\\n\\n- **Common Pitfalls to Avoid**:\\n  - **Information Overload**: Too much detail can confuse the model.\\n  - **Open-Ended Questions**: Vague questions lead to imprecise responses.\\n  - **Poor Use of Constraints**: Lack of boundaries can result in ineffective outputs.',\n",
       " 'quiz_questions': 'Here are five multiple-choice questions based on the summary of prompt engineering:\\n\\n1. **What is the primary purpose of prompt engineering in natural language processing (NLP)?**\\n   - A) To create complex algorithms\\n   - B) To guide AI in generating various outputs\\n   - C) To analyze large datasets\\n   - D) To develop new programming languages  \\n   **Correct Answer: B) To guide AI in generating various outputs**\\n\\n2. **Which of the following is NOT an example of a prompt type mentioned in the summary?**\\n   - A) Text Prompts\\n   - B) Code Prompts\\n   - C) Image Prompts\\n   - D) Audio Prompts  \\n   **Correct Answer: D) Audio Prompts**\\n\\n3. **What is a key tip for effective prompt engineering?**\\n   - A) Use as many words as possible\\n   - B) Avoid specifying the model\\'s role\\n   - C) Be concise and avoid ambiguity\\n   - D) Provide vague instructions  \\n   **Correct Answer: C) Be concise and avoid ambiguity**\\n\\n4. **In the context of prompt engineering, what does \"Few-Shot Prompting\" refer to?**\\n   - A) Providing no examples for guidance\\n   - B) Using multiple examples to enhance task performance\\n   - C) Asking a single question to the model\\n   - D) Giving the model a complex task without any context  \\n   **Correct Answer: B) Using multiple examples to enhance task performance**\\n\\n5. **What common pitfall should be avoided in prompt engineering?**\\n   - A) Providing clear and specific instructions\\n   - B) Using open-ended questions that lead to vague responses\\n   - C) Maintaining a coherent tone and flow\\n   - D) Specifying the model\\'s role  \\n   **Correct Answer: B) Using open-ended questions that lead to vague responses**'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = final_chain.invoke({'study_material': study_material})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bd305c-b2d2-4c0b-ab28-9173e219dcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of Prompt Engineering\n",
       "\n",
       "- **Definition**: \n",
       "  - Prompt engineering is a practice in natural language processing (NLP) where text describes the task for AI to perform, guiding the AI to generate various outputs.\n",
       "\n",
       "- **Purpose of Prompts**: \n",
       "  - Prompts are detailed descriptions of desired outputs, defining user-model interactions and guiding AI performance.\n",
       "\n",
       "- **Effectiveness**: \n",
       "  - The success of prompt engineering depends on the design and clarity of the prompt.\n",
       "\n",
       "- **Examples of Prompts**:\n",
       "  - **Text Prompts**: \n",
       "    - Questions or tasks for language models (e.g., \"What’s the difference between generative AI and traditional AI?\").\n",
       "  - **Code Prompts**: \n",
       "    - Instructions for coding tasks (e.g., \"Write a function to multiply two numbers.\").\n",
       "  - **Image Prompts**: \n",
       "    - Descriptions for generating images (e.g., \"Depict a dog in a car wearing sunglasses.\").\n",
       "  \n",
       "- **Tips for Effective Prompt Engineering**:\n",
       "  - **Role Playing**: Specify the model's role to tailor interactions.\n",
       "  - **Clarity**: Be concise and avoid ambiguity.\n",
       "  - **Specification**: Provide clear and specific instructions.\n",
       "  - **Consistency**: Maintain a coherent tone and flow.\n",
       "\n",
       "- **Elements of a Prompt**:\n",
       "  - **Instruction**: Task directive for the model.\n",
       "  - **Context**: Background information for understanding.\n",
       "  - **Input Data**: Data provided for processing.\n",
       "  - **Output Indicator**: Expected output format specification.\n",
       "\n",
       "- **Standard Prompt Patterns**:\n",
       "  - **User-Model Interaction**: Direct instruction-response format.\n",
       "  - **Few-Shot Prompting**: Providing examples to guide the model.\n",
       "  - **Question-and-Answer Pattern**: Structured Q&A format.\n",
       "\n",
       "- **Advanced Prompting Techniques**:\n",
       "  - **Zero-Shot Prompting**: Task performance without specific training.\n",
       "  - **Few-Shot Prompting/In-Context Learning**: Using examples to enhance task performance.\n",
       "  - **Chain-of-Thought (CoT)**: Breaking down complex tasks into steps for better reasoning.\n",
       "\n",
       "- **Common Pitfalls to Avoid**:\n",
       "  - **Information Overload**: Too much detail can confuse the model.\n",
       "  - **Open-Ended Questions**: Vague questions lead to imprecise responses.\n",
       "  - **Poor Use of Constraints**: Lack of boundaries can result in ineffective outputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response[\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0db1ad9-a0e3-4678-9109-12a46d94620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are five multiple-choice questions based on the summary of prompt engineering:\n",
       "\n",
       "1. **What is the primary purpose of prompt engineering in natural language processing (NLP)?**\n",
       "   - A) To create complex algorithms\n",
       "   - B) To guide AI in generating various outputs\n",
       "   - C) To analyze large datasets\n",
       "   - D) To develop new programming languages  \n",
       "   **Correct Answer: B) To guide AI in generating various outputs**\n",
       "\n",
       "2. **Which of the following is NOT an example of a prompt type mentioned in the summary?**\n",
       "   - A) Text Prompts\n",
       "   - B) Code Prompts\n",
       "   - C) Image Prompts\n",
       "   - D) Audio Prompts  \n",
       "   **Correct Answer: D) Audio Prompts**\n",
       "\n",
       "3. **What is a key tip for effective prompt engineering?**\n",
       "   - A) Use as many words as possible\n",
       "   - B) Avoid specifying the model's role\n",
       "   - C) Be concise and avoid ambiguity\n",
       "   - D) Provide vague instructions  \n",
       "   **Correct Answer: C) Be concise and avoid ambiguity**\n",
       "\n",
       "4. **In the context of prompt engineering, what does \"Few-Shot Prompting\" refer to?**\n",
       "   - A) Providing no examples for guidance\n",
       "   - B) Using multiple examples to enhance task performance\n",
       "   - C) Asking a single question to the model\n",
       "   - D) Giving the model a complex task without any context  \n",
       "   **Correct Answer: B) Using multiple examples to enhance task performance**\n",
       "\n",
       "5. **What common pitfall should be avoided in prompt engineering?**\n",
       "   - A) Providing clear and specific instructions\n",
       "   - B) Using open-ended questions that lead to vague responses\n",
       "   - C) Maintaining a coherent tone and flow\n",
       "   - D) Specifying the model's role  \n",
       "   **Correct Answer: B) Using open-ended questions that lead to vague responses**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response[\"quiz_questions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429d0db-ba8e-4368-ad70-17b1a2be20d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
