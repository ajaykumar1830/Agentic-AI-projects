{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf5cf6-91a6-4ca4-8a6c-6dc4bfbdf489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "#Import other libraries\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce3b1d-503d-493f-91e3-eae9a79e2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateToken():\n",
    "    cwd = os.getcwd()\n",
    "    dotenv_path = os.path.join(cwd,\"path to auth.env file\")\n",
    "    load_dotenv(dotenv_path)\n",
    "    time_generated_str = os.getenv(\"TIME_GENERATED\")\n",
    "    print(time_generated_str)\n",
    "    TimeGenerated = datetime.fromisoformat(time_generated_str)\n",
    "    if TimeGenerated + timedelta(minutes=60) < datetime.now():\n",
    "        token_url = os.getenv(\"ISSUER_URL\")+\"/v1/token\"\n",
    "        print(token_url)\n",
    "        client_id = os.getenv(\"CLIENT_ID\")\n",
    "        client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "        scope = os.getenv(\"SCOPE\")\n",
    "        # Define the payload\n",
    "        payload = {\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"scope\": scope\n",
    "        }\n",
    "        # Make the POST request\n",
    "        response = requests.post(token_url, data=payload, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"})\n",
    "        print(response.json())\n",
    "        repsonse_json = response.json()\n",
    "        token = repsonse_json[\"access_token\"]\n",
    "        TimeGenerated = datetime.now()\n",
    "        # Update the .env file with the new token\n",
    "        with open('C:/Users/AK57630/Introduction to LangChain for Agentic AI/Module 2/auth.env', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        with open('.env', 'w') as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"OPENAI_API_KEY=\"):\n",
    "                    file.write(f\"OPENAI_API_KEY={token}\\n\")\n",
    "                elif line.startswith(\"TIME_GENERATED=\"):\n",
    "                    file.write(f\"TIME_GENERATED={TimeGenerated}\\n\")\n",
    "                else:\n",
    "                    file.write(line)    \n",
    "        os.environ.pop(\"OPENAI_API_KEY\", None)                \n",
    "        load_dotenv()\n",
    "        print(os.getenv(\"OPENAI_API_KEY\"))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af125d22-c867-49a6-ab2e-0ad6ec013665",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8b556-cb16-4fc3-ab38-5b66582a5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "DOC_PATH = os.path.join(cwd,'Howard_Roark_speech.pdf')\n",
    "#DOC_PATH = \"./Howard_Roark_speech.pdf\"\n",
    "CHROMA_PATH = \"path to chroma_db\"\n",
    "loader = PyPDFLoader(DOC_PATH)\n",
    "pages = loader.load()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ceffc-d0d6-44d9-98cd-a427cae0b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the doc into smaller chunks i.e. chunk_size=500\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65a578-451c-427a-90b3-8a50bbfd2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "dotenv_path = os.path.join(cwd,'path to auth.env file')\n",
    "load_dotenv(dotenv_path)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "header_name = os.getenv('AI_GATEWAY_HEADER_NAME')\n",
    "header_value = os.getenv('AI_GATEWAY_REGISTRATION_ID')\n",
    "headers = {\n",
    "    header_name: header_value\n",
    "    }\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\",default_headers=headers)\n",
    "db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH,collection_name=\"my_rag_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02b3e8-33d0-426d-8aef-6218879c4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Retrieval and Generation Process -----\n",
    "\n",
    "# this is an example of a user question (query)\n",
    "#query = 'what are the characteristics of a creator?'\n",
    "query = 'Who is a parasite?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f542363-a4ab-4879-ba44-1b502820061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve context - top 5 most relevant (closests) chunks to the query vector \n",
    "# (by default Langchain is using cosine distance metric)\n",
    "docs_chroma = db_chroma.similarity_search_with_score(query, k=2)\n",
    "\n",
    "# generate an answer based on given user query and retrieved context information\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c4f16-a8ed-49ff-b0c1-cf37461ced41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use a prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Answer the question based on the above context: {question}.\n",
    "Provide a detailed answer.\n",
    "Don’t justify your answers.\n",
    "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
    "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4297afe2-ae4f-4634-9073-a4ae1b1f7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load retrieved context and user query in the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e957aae-a7ef-4db9-8a77-a9b1f5f41983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call LLM model to generate the answer based on the given context and query\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0,default_headers=headers)\n",
    "response_text = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c05b6-e14f-4715-a18c-47817e167991",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_text.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf77e1-0dcd-420c-9a1a-96ccec152b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
